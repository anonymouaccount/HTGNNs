{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raniaabidi/HTGNNs/blob/main/HTGNN_Amazon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk2fcofrVx0H",
        "outputId": "bbe21b5a-216d-4bca-cd75-aff8974f75c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fVqnAbFV2t_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['LC_ALL'] = 'en_US.UTF-8'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocEmlOjqoEdN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "ratings = pd.read_csv('/content/drive/MyDrive/ratings_Beauty.csv')\n",
        "\n",
        "# Convert timestamp to datetime\n",
        "ratings['timestamp'] = pd.to_datetime(ratings['Timestamp'], unit='s')\n",
        "\n",
        "# Sort by timestamp\n",
        "ratings = ratings.sort_values(by='timestamp')\n",
        "\n",
        "# Split the data into train and test sets\n",
        "train_data, test_data = train_test_split(ratings, test_size=0.2, shuffle=False)\n",
        "\n",
        "# Create graph structures with numeric timestamps\n",
        "def create_graph(data):\n",
        "    G = nx.DiGraph()\n",
        "    for _, row in data.iterrows():\n",
        "        G.add_edge(row['UserId'], row['ProductId'], timestamp=row['timestamp'].timestamp())\n",
        "    return G\n",
        "\n",
        "train_graph = create_graph(train_data)\n",
        "test_graph = create_graph(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8VMfSJSEaPN",
        "outputId": "244cd762-1261-4b48-a8fa-318a468eb51b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl.metadata (64 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/64.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.13.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n",
            "Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aOJydAXfalRG",
        "outputId": "e465db21-61c7-45bc-c19d-c708db315d2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "\n",
        "# Convert NetworkX graph to PyTorch Geometric Data object\n",
        "def convert_to_pyg_data(graph, num_features=8):\n",
        "    nodes = list(graph.nodes())\n",
        "    node_mapping = {node: i for i, node in enumerate(nodes)}\n",
        "    edge_index = torch.tensor([[node_mapping[u], node_mapping[v]] for u, v in graph.edges]).t().contiguous()\n",
        "    edge_time = torch.tensor([graph[u][v]['timestamp'] for u, v in graph.edges], dtype=torch.float)\n",
        "\n",
        "    # Create a feature matrix with fixed number of features per node\n",
        "    x = torch.randn(len(nodes), num_features)\n",
        "\n",
        "    # Random labels for the nodes (binary classification: 0 or 1)\n",
        "    y = torch.randint(0, 2, (len(nodes),))\n",
        "\n",
        "    data = Data(x=x, edge_index=edge_index, edge_time=edge_time, y=y)\n",
        "    return data\n",
        "\n",
        "train_data_pyg = convert_to_pyg_data(train_graph)\n",
        "test_data_pyg = convert_to_pyg_data(test_graph)\n",
        "\n",
        "train_loader = DataLoader([train_data_pyg], batch_size=1, shuffle=True)\n",
        "test_loader = DataLoader([test_data_pyg], batch_size=1, shuffle=False)\n",
        "\n",
        "class HTGNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(HTGNN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 8)\n",
        "        self.conv2 = GCNConv(8 + 8, out_channels)\n",
        "        self.time_embedding = torch.nn.Embedding(365, 8)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_time):\n",
        "        print(f'Input x shape: {x.shape}')\n",
        "        print(f'Edge index shape: {edge_index.shape}')\n",
        "        print(f'Edge time shape: {edge_time.shape}')\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        print(f'x after conv1 shape: {x.shape}')\n",
        "\n",
        "        # Embedding for the edge times\n",
        "        time_embeds = self.time_embedding((edge_time.long() % 365).view(-1, 1)).view(-1, 8)\n",
        "        print(f'time_embeds shape: {time_embeds.shape}')\n",
        "\n",
        "        # Average the edge time embeddings per node\n",
        "        node_time_embeds = torch.zeros_like(x)\n",
        "        for i in range(edge_index.size(1)):\n",
        "            node_time_embeds[edge_index[0, i]] += time_embeds[i]\n",
        "        print(f'node_time_embeds shape: {node_time_embeds.shape}')\n",
        "\n",
        "        x = torch.cat([x, node_time_embeds], dim=1)\n",
        "        print(f'x after concatenation shape: {x.shape}')\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        print(f'x after conv2 shape: {x.shape}')\n",
        "\n",
        "        return x\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "model = HTGNN(in_channels=train_data_pyg.num_node_features, out_channels=2)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "koFEAC3IautT",
        "outputId": "27ce7e31-f653-480a-d7e2-943f89e53004"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input x shape: torch.Size([1214002, 8])\n",
            "Edge index shape: torch.Size([2, 1618456])\n",
            "Edge time shape: torch.Size([1618456])\n",
            "x after conv1 shape: torch.Size([1214002, 8])\n",
            "time_embeds shape: torch.Size([1618456, 8])\n",
            "node_time_embeds shape: torch.Size([1214002, 8])\n",
            "x after concatenation shape: torch.Size([1214002, 16])\n",
            "x after conv2 shape: torch.Size([1214002, 2])\n"
          ]
        }
      ],
      "source": [
        "# Training function\n",
        "def train(model, loader, optimizer, loss_fn):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.edge_index, data.edge_time)\n",
        "        loss = loss_fn(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    for data in loader:\n",
        "        out = model(data.x, data.edge_index, data.edge_time)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == data.y).sum().item()\n",
        "    return correct / len(loader.dataset)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(100):\n",
        "    train_loss = train(model, train_loader, optimizer, loss_fn)\n",
        "    test_acc = evaluate(model, test_loader)\n",
        "    print(f'Epoch {epoch}, Loss: {train_loss}, Test Accuracy: {test_acc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qP5dm6FpNHs"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Function to calculate MRR\n",
        "def mrr_score(y_true, y_pred):\n",
        "    order = np.argsort(y_pred)[::-1]\n",
        "    ranks = np.where(y_true[order] == 1)[0] + 1\n",
        "    return np.mean(1.0 / ranks)\n",
        "\n",
        "# Function to calculate NDCG\n",
        "def ndcg_score(y_true, y_pred, k=10):\n",
        "    order = np.argsort(y_pred)[::-1]\n",
        "    y_true = np.take(y_true, order[:k])\n",
        "\n",
        "    gains = 2 ** y_true - 1\n",
        "    discounts = np.log2(np.arange(2, k + 2))\n",
        "    dcg = np.sum(gains / discounts)\n",
        "\n",
        "    ideal_gains = 2 ** np.sort(y_true)[::-1] - 1\n",
        "    idcg = np.sum(ideal_gains / discounts)\n",
        "\n",
        "    return dcg / idcg if idcg > 0 else 0.0\n",
        "\n",
        "# Evaluation function with metrics\n",
        "def evaluate_with_metrics(model, loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    for data in loader:\n",
        "        out = model(data.x, data.edge_index, data.edge_time)\n",
        "        pred = out.argmax(dim=1)\n",
        "        all_preds.append(pred.detach().cpu().numpy())\n",
        "        all_labels.append(data.y.detach().cpu().numpy())\n",
        "\n",
        "    all_preds = np.concatenate(all_preds)\n",
        "    all_labels = np.concatenate(all_labels)\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average='macro')\n",
        "    recall = recall_score(all_labels, all_preds, average='macro')\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    mrr = mrr_score(all_labels, all_preds)\n",
        "    ndcg = ndcg_score(all_labels, all_preds)\n",
        "\n",
        "    return accuracy, precision, recall, f1, mrr, ndcg\n",
        "\n",
        "# Function to calculate just the accuracy\n",
        "def calculate_accuracy(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in loader:\n",
        "        out = model(data.x, data.edge_index, data.edge_time)\n",
        "        pred = out.argmax(dim=1)\n",
        "        correct += (pred == data.y).sum().item()\n",
        "        total += data.y.size(0)\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "accuracy, precision, recall, f1, mrr, ndcg = evaluate_with_metrics(model, test_loader)\n",
        "print(f' NDCG: {ndcg}, Precision: {precision}, Recall: {recall}, F1-Score: {f1}')\n",
        "\n",
        "accuracy = calculate_accuracy(model, test_loader)\n",
        "print(f'Final Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpO2TgsipZUL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "random_accuracy = 0.5\n",
        "n = len(test_loader.dataset)\n",
        "\n",
        "se = np.sqrt(random_accuracy * (1 - random_accuracy) / n)\n",
        "\n",
        "z_score = (accuracy - random_accuracy) / se\n",
        "\n",
        "p_value = 2 * norm.sf(np.abs(z_score))\n",
        "\n",
        "print(f\"P-value: {p_value}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}